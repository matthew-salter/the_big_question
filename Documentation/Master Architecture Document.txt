🔧 MASTER ARCHITECTURE DOCUMENT

# Project Name: Structured Report Generation Engine

## 1. Mission
To build a modular, schema-driven system that ingests natural language questions (with optional voice input or context), classifies their **topic**, **intent**, and **structure**, and generates a publishable report using structured, AI-generated assets.

The system supports full human override, asset regeneration, and prompt-based orchestration via automation.

---

## 2. User Inputs

- **Primary Question**  
  Free-text user input (e.g. “What will the price of lithium be in 12 months?”)

- **Voice Transcript**  
  Rich contextual background collected via assistant interface (e.g. “concerned about freight disruptions and China policy”)

- **Question Topic**  
  Domain or subject matter (e.g. Commodity, Education, Finance)

- **Override Controls (Optional)**  
  Sections, sub-sections, tone, preferred structure, etc.

- **Supporting Documents (Optional)**  
  PDFs, prior reports, baselines, or links used to enrich prompts. Injected conditionally as weighted blocks.

---

## 3. System Hierarchy

### A. Question Topics (Content Layer)
Defines the *subject matter* of the question.
- Commodity
- Education
- Healthcare
- Finance
- Technology
- Logistics
- Workforce
- Energy

### B. Question Types (Intent Layer)
Classifies what the user is asking for.
- Descriptive
- Comparative
- Predictive
- Prescriptive
- Diagnostic
- Evaluative
- Speculative
- Nonsense / Metaphorical

### C. Report Types (Output Structure Layer)
Specifies the report’s formatting logic.
- Predictive Report *(weighted-effect calculation with % makeup and scenario logic)*
- Comparison Report
- Cost Structure Report
- Scenario Risk Report
- Impact Cascade Report
- Recommendation Report
- Root Cause Report
- Explainer Report

### D. Section Types (Structural Elements)
Report sections (templated per report type).
- Market Baseline
- Driving Factors
- Scenario Forecast
- Strategic Implications
- Scorecard
- How-To Guide

### E. Asset Types
Structured outputs collected per section or report-wide.
- **Universal**: `report_title`, `executive_summary`, `conclusion`, `section_header`, `section_summary`
- **Conditional**:
  - `chart_data`, `chart_caption`
  - `statistical_bullet_points`
  - `quote_extraction`
  - `scenario_table`
  - `recommendation_list`
  - `root_cause_map`
  - `comparison_matrix`
  - `scorecard`
  - `change_low`, `change_high`, `makeup_percent`, `effect_calc`

---

## 4. Core System Architecture

### Zapier Layer
- Triggers: Typeform/Webhook/File Upload
- Sends inputs and metadata to Python backend
- Receives outputs for Google Docs, Sheets, Notion, Slack, etc.

### Python Backend (“The Brain”)
- Classifies question topic + type
- Selects matching report type
- Builds a structured JSON `report_manifest`
- Injects all variables into prompt templates
- Sends prompts to OpenAI
- Stores output per section
- Handles revisions, versioning, and overrides

### AI Layer
- Executes prompt templates statelessly
- Returns JSON-structured responses
- Resolves conflicts between structure and input intent
- Integrates `supporting_documents` only if explicitly provided
- Aggregates multi-source signals (for more stable predictions)

### Storage Layer
- Manifest per report (JSON)
- Section assets (modular JSON)
- Final structured CSV for design template pipeline
- Versioned GDocs for editing/review

### Optional UI (Later)
- Report configuration panel (Retool, Streamlit, Flask)
- Allows input control, manual override, and partial regeneration

---

## 5. Technical Paths

### New Report Flow
- Capture: Question + Context
- Classify: Topic + Question Type
- Match: Report Type
- Inject: Prompt structure + schema
- Output: JSON assets per section
- Assemble: Final report document

### Section Regeneration
- Human flags section → System re-runs just that prompt with full retained context

### Human Feedback Flow
- Editable GDoc with revision flags
- Feedback piped into override engine
- AI regenerates section/sub-section without disturbing structure

### Recurring Reports
- Re-use original manifest
- Retain schema and section logic
- Re-run Prompt 1 + data sources
- Forecast drift constrained by prior tolerances unless override justified

### Document Enrichment
- External docs → parsed → injected into prompt
- Used to inform but not override structured insight logic

---

## 6. Example JSON Manifest

```json
{
  "report_id": "lithium_price_china_q1_2025",
  "question": "What will the price of lithium be in China next quarter?",
  "question_topic": "Commodity",
  "question_type": "Predictive",
  "report_type": "Predictive Report",
  "structure_overrides": {
    "sections": 5,
    "subsections": 2,
    "tone": "analytical"
  },
  "sections": [
    {
      "id": "market_baseline",
      "title": "Current Lithium Market Conditions",
      "assets": ["section_summary", "chart_data", "change_low", "change_high"]
    },
    {
      "id": "forecast",
      "title": "Forecasted Supply and Demand Factors",
      "assets": ["scenario_table", "effect_calc"]
    }
  ],
  "status": "in_progress"
}

---

7. Visual Maps

flowchart TD
    Q[Question + Context] --> QT[Classify Topic + Type]
    QT --> RT[Select Report Type]
    RT --> SCH[Load Manifest Template]
    SCH --> PROMPTS[Send Prompt Blocks to AI]
    PROMPTS --> OUT[Collect JSON Assets]
    OUT --> DOC[Assemble Final Report]
    DOC --> REVIEW[Human Feedback?]
    REVIEW -- Yes --> FIX[Section Regeneration]
    REVIEW -- No --> DONE[Deliver & Store]

---

System Hierarchy

graph TD
    Q[Question] --> TQ[Question Topic]
    Q --> QT[Question Type]
    QT --> RT[Report Type]
    RT --> ST[Section Type]
    ST --> AS[Asset Type]

---

8. Development Status
Phase 1: Core Flow (✓ Completed)
Prompt 1 working end-to-end
Manifest builder in place
Zapier trigger stable
AI prompt injection modular

Phase 2: Revision Logic (🚧 In Progress)
Flagged section regeneration
Feedback-to-regeneration routing

Phase 3: Expansion
Add multi-topic support (non-Commodity)
Add non-Predictive report templates
Add override UI
Add PDF and chart rendering layer
